[
  {
    "moduleName": "default",
    "type": "image",
    "category": null,
    "icon": null,
    "title": "Getting Started",
    "templates": [
      {
        "name": "gligen_textbox_example",
        "title": "Gligen Textbox",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images by precisely placing objects via textboxes.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/gligen/",
        "tags": ["Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 2974264852,
        "vram": 4080218931
      },
      {
        "name": "area_composition_square_area_for_subject",
        "title": "Area Composition: Subject Square Area",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images with consistent subject placement using area composition.",
        "tags": ["Text-to-Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/area_composition/#increasing-consistency-of-images-with-area-composition",
        "size": 2469606195,
        "vram": 5927054868
      },
      {
        "name": "latent_upscale_different_prompt_model",
        "title": "Latent Upscale with Different Prompts",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Change prompts during generation to upscale images.",
        "thumbnailVariant": "zoomHover",
        "tags": ["Upscale", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/#more-examples",
        "size": 4262755041,
        "vram": 5153960755
      },
      {
        "name": "embedding_example",
        "title": "Embedding",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Use textual inversion to generate images with a consistent style.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/textual_inversion_embeddings/",
        "tags": ["Text-to-Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 5218385265,
        "vram": 4123168604
      },
      {
        "name": "area_composition",
        "title": "Area Composition",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images by defining and controlling composition areas.",
        "tags": ["Text-to-Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/area_composition/",
        "size": 2469606195,
        "vram": 6184752906
      },
      {
        "name": "hiresfix_latent_workflow",
        "title": "Upscale",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Upscale images by enhancing quality in latent space.",
        "thumbnailVariant": "compareSlider",
        "tags": ["Upscale", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/",
        "size": 2136746230,
        "vram": 3929895076
      },
      {
        "name": "esrgan_example",
        "title": "ESRGAN",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Upscale images using the ESRGAN model for higher quality.",
        "thumbnailVariant": "compareSlider",
        "tags": ["Upscale", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/",
        "size": 2201170739,
        "vram": 6442450944
      },
      {
        "name": "hiresfix_esrgan_workflow",
        "title": "HiresFix ESRGAN Workflow",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Use the ESRGAN model for upscaling during intermediate generation steps.",
        "thumbnailVariant": "compareSlider",
        "tags": ["Upscale", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/#non-latent-upscaling",
        "size": 2201170739,
        "vram": 6442450944
      },
      {
        "name": "2_pass_pose_worship",
        "title": "Pose ControlNet Two-Pass",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Use ControlNet to guide image generation with pose references.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#pose-controlnet",
        "size": 4660039516,
        "vram": 6442450944
      },
      {
        "name": "depth_t2i_adapter",
        "title": "Depth T2I Adapter",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Guide image generation using T2I Adapter with depth information.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image", "Text-to-Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#t2i-adapter-vs-controlnets",
        "size": 2523293286,
        "vram": 6442450944
      },
      {
        "name": "mixing_controlnets",
        "title": "Mixing ControlNets",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images by combining multiple ControlNet models.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image", "Text-to-Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#mixing-controlnets",
        "size": 3328599654,
        "vram": 6442450944
      },
      {
        "name": "image2image",
        "title": "Image-to-Image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Transform an existing image with a text prompt.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/image-to-image",
        "tags": ["Image-to-Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 2136746230,
        "vram": 3092376453,
        "thumbnailVariant": "hoverDissolve"
      },
      {
        "name": "lora",
        "title": "LoRA",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images with professional style or subject using LoRA models.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/lora",
        "tags": ["Text-to-Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 2437393940,
        "vram": 3092376453
      },
      {
        "name": "lora_multiple",
        "title": "Multiple LoRA",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images by combining multiple LoRA models.",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/lora",
        "tags": ["Text-to-Image", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 2437393940,
        "vram": 3350074491
      },
      {
        "name": "inpaint_model_outpainting",
        "title": "Outpainting",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Expand images beyond their original boundaries.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/inpaint",
        "tags": ["Outpainting", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 5218385265,
        "vram": 4101693768
      },
      {
        "name": "controlnet_example",
        "title": "Scribble ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Guide image generation via ControlNet using scribble reference images.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/",
        "size": 3189013217,
        "vram": 6442450944
      },
      {
        "name": "depth_controlnet",
        "title": "Depth ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Guide image generation using ControlNet with depth information.",
        "thumbnailVariant": "hoverDissolve",
        "tags": ["ControlNet", "Image", "Text-to-Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#t2i-adapter-vs-controlnets",
        "size": 2888365507,
        "vram": 6442450944
      },
      {
        "name": "inpaint_example",
        "title": "Inpaint",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Edit specific parts of images seamlessly.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/basic/inpaint",
        "tags": ["Inpainting", "Image"],
        "models": ["SD1.5", "Stability"],
        "date": "2025-03-01",
        "size": 5218385265,
        "vram": 4101693768,
        "status": "archived",
        "usage": 88
      }
    ]
  },
  {
    "moduleName": "default",
    "type": "video",
    "category": "Generation Type",
    "icon": "icon-[lucide--film]",
    "title": "Video",
    "templates": [
      {
        "name": "api_pika_i2v",
        "title": "Pika: Image-to-Video",
        "description": "Use Pika AI to generate smooth animated videos from a single still image.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image-to-Video", "Video", "API"],
        "models": ["Pika"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "openSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "api_pika_scene",
        "title": "Pika Scene: Image-to-Video",
        "description": "Use Pika Scene to generate videos containing multiple input images.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tags": ["Image-to-Video", "Video", "API"],
        "models": ["Pika"],
        "date": "2025-03-01",
        "tutorialUrl": "",
        "openSource": false,
        "size": 0,
        "vram": 0
      },
      {
        "name": "mochi_text_to_video_example",
        "title": "Mochi Text-to-Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos from text prompts using the Mochi model.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/mochi/",
        "tags": ["Text-to-Video", "Video"],
        "models": ["Mochi"],
        "date": "2025-03-01",
        "size": 30762703258,
        "vram": 30762703258
      },
      {
        "name": "image_to_video",
        "title": "SVD Image-to-Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate video from a still image.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/video/#image-to-video",
        "tags": ["Image-to-Video", "Video"],
        "models": ["SVD", "Stability"],
        "date": "2025-03-01",
        "size": 9556302234,
        "vram": 9556302234
      }
    ]
  },
  {
    "moduleName": "default",
    "type": "video",
    "category": "GENERATION TYPE",
    "icon": "icon-[lucide--film]",
    "title": "Video",
    "templates": []
  }
]
