{
  "id": "73611c02-cdf1-4ae8-a41a-d9c057e201ed",
  "revision": 0,
  "last_node_id": 113,
  "last_link_id": 145,
  "nodes": [
    {
      "id": 95,
      "type": "UNETLoader",
      "pos": [
        10729.999333976715,
        602.0000773829366
      ],
      "size": [
        324,
        118.65625
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            136
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "UNETLoader",
        "cnr_id": "comfy-core",
        "enableTabs": false,
        "hasSecondTab": false,
        "models": [
          {
            "directory": "diffusion_models",
            "name": "z_image_turbo_bf16.safetensors",
            "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/diffusion_models/z_image_turbo_bf16.safetensors"
          }
        ],
        "secondTabOffset": 80,
        "secondTabText": "Send Back",
        "secondTabWidth": 65,
        "tabWidth": 65,
        "tabXOffset": 10,
        "ver": "0.3.73"
      },
      "widgets_values": [
        "z_image_turbo_bf16.safetensors",
        "default"
      ]
    },
    {
      "id": 96,
      "type": "CLIPLoader",
      "pos": [
        10729.999333976715,
        769.9999945399496
      ],
      "size": [
        324,
        150.65625
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "showAdvanced": false,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            140
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPLoader",
        "cnr_id": "comfy-core",
        "enableTabs": false,
        "hasSecondTab": false,
        "models": [
          {
            "directory": "text_encoders",
            "name": "qwen_3_4b.safetensors",
            "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors"
          }
        ],
        "secondTabOffset": 80,
        "secondTabText": "Send Back",
        "secondTabWidth": 65,
        "tabWidth": 65,
        "tabXOffset": 10,
        "ver": "0.3.73"
      },
      "widgets_values": [
        "qwen_3_4b.safetensors",
        "lumina2",
        "default"
      ]
    },
    {
      "id": 101,
      "type": "EmptyLatentImage",
      "pos": [
        11150.001154259919,
        602.0000773829366
      ],
      "size": [
        336,
        144
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            145
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        1080,
        1920,
        1
      ]
    },
    {
      "id": 103,
      "type": "CLIPTextEncode",
      "pos": [
        11582.003397274082,
        602.0000503510612
      ],
      "size": [
        350,
        410
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 140
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            137,
            142
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode",
        "cnr_id": "comfy-core",
        "enableTabs": false,
        "hasSecondTab": false,
        "secondTabOffset": 80,
        "secondTabText": "Send Back",
        "secondTabWidth": 65,
        "tabWidth": 65,
        "tabXOffset": 10,
        "ver": "0.3.73"
      },
      "widgets_values": [
        "Editorial shot: On a volcanic black sand beach with a dark overcast sky.\n\nLow side-angle: Male model is in a deep squat, knees wide, head resting in one hand with a brooding, sharp gaze.\n\nHair: Ultra-short platinum blonde buzz cut.\n\nWardrobe: light-blue transparent oval sunglasses, oversized black wool chunky-knit sweater, baggy cargo trousers, climbing shoes. \n\nLighting: Theatrical cold blue moonlighting contrasted by a single sharp, warm orange spotlight on the face. Shot on Fujifilm GFX 100S, 110mm f/2 lens\n\nVibe: Paganism, futuristic tech-wear."
      ]
    },
    {
      "id": 94,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        12014.000450168121,
        602.0000773829366
      ],
      "size": [
        348,
        80
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 136
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            141
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "ModelSamplingAuraFlow",
        "cnr_id": "comfy-core",
        "enableTabs": false,
        "hasSecondTab": false,
        "secondTabOffset": 80,
        "secondTabText": "Send Back",
        "secondTabWidth": 65,
        "tabWidth": 65,
        "tabXOffset": 10,
        "ver": "0.3.64"
      },
      "widgets_values": [
        3
      ]
    },
    {
      "id": 102,
      "type": "KSampler",
      "pos": [
        12013.999585148104,
        734.0000238771079
      ],
      "size": [
        348,
        663.328125
      ],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 141
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 142
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 143
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 145
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            138
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler",
        "cnr_id": "comfy-core",
        "enableTabs": false,
        "hasSecondTab": false,
        "secondTabOffset": 80,
        "secondTabText": "Send Back",
        "secondTabWidth": 65,
        "tabWidth": 65,
        "tabXOffset": 10,
        "ver": "0.3.64"
      },
      "widgets_values": [
        222678399973641,
        "randomize",
        8,
        1,
        "res_multistep",
        "simple",
        1
      ]
    },
    {
      "id": 98,
      "type": "VAEDecode",
      "pos": [
        12458.0013858732,
        602.0000773829366
      ],
      "size": [
        225,
        72
      ],
      "flags": {
        "collapsed": false
      },
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 138
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 139
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            144
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode",
        "cnr_id": "comfy-core",
        "enableTabs": false,
        "hasSecondTab": false,
        "secondTabOffset": 80,
        "secondTabText": "Send Back",
        "secondTabWidth": 65,
        "tabWidth": 65,
        "tabXOffset": 10,
        "ver": "0.3.64"
      },
      "widgets_values": []
    },
    {
      "id": 99,
      "type": "ConditioningZeroOut",
      "pos": [
        11590,
        1100
      ],
      "size": [
        234.1875,
        8
      ],
      "flags": {
        "collapsed": true
      },
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 137
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            143
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "ConditioningZeroOut",
        "cnr_id": "comfy-core",
        "enableTabs": false,
        "hasSecondTab": false,
        "secondTabOffset": 80,
        "secondTabText": "Send Back",
        "secondTabWidth": 65,
        "tabWidth": 65,
        "tabXOffset": 10,
        "ver": "0.3.73"
      },
      "widgets_values": []
    },
    {
      "id": 100,
      "type": "SaveImage",
      "pos": [
        12458.00052085318,
        722.000141783663
      ],
      "size": [
        324,
        664
      ],
      "flags": {
        "collapsed": false
      },
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 144
        }
      ],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "Z-Image-Turbo"
      ]
    },
    {
      "id": 108,
      "type": "MarkdownNote",
      "pos": [
        10358.00006963736,
        542.0000181506979
      ],
      "size": [
        300,
        88
      ],
      "flags": {
        "collapsed": false
      },
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "‚ÑπÔ∏è Info",
      "properties": {},
      "widgets_values": [
        "This is a basic **Text to Image** workflow with the Z Image Turbo model."
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 107,
      "type": "MarkdownNote",
      "pos": [
        10358.00006963736,
        710.0000434352132
      ],
      "size": [
        300,
        370.96875
      ],
      "flags": {
        "collapsed": false
      },
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "üîç Core Concept",
      "properties": {},
      "widgets_values": [
        "## Basic Diffusion\n\nDiffusion models transform random noise into a clear image based on a text prompt. Trained to predict and remove noise from data, they refine images step-by-step during inference: start with noise, iteratively denoise over multiple steps, and output the described image.\n\nZ-Image Turbo is a distilled 6B-parameter model that produces high-quality photorealistic images in just ~8 steps (sub-second on capable hardware), faster than traditional models requiring 20‚Äì50+ steps."
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 104,
      "type": "MarkdownNote",
      "pos": [
        10706.00021855484,
        1501.9999927189965
      ],
      "size": [
        372,
        415.171875
      ],
      "flags": {
        "collapsed": false
      },
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Step 1 - Load the Models ‚¨áÔ∏è",
      "properties": {},
      "widgets_values": [
        "Load these three essentials:\n\n## Diffusion Model\n\nDenoises noise into images. (z_image_turbo_bf16.safetensors)\n\n\n## Text Encoder\n\nTurns your prompt words into guidance vectors (like an advanced CLIP) (qwen_3_4b.safetensors)\n\n\n## VAE (ae.safetensors)\nCompresses images to latent space for faster diffusion, then decodes back to pixels."
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 111,
      "type": "MarkdownNote",
      "pos": [
        11990.000469726227,
        1501.9999927189965
      ],
      "size": [
        408,
        519.171875
      ],
      "flags": {
        "collapsed": false
      },
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Step 4 - Sampling üñºÔ∏è",
      "properties": {},
      "widgets_values": [
        "## Model Sampling (e.g., AuraFlow)\n\nModelSamplingAuraFlow node: Optimizes timing/shift for Turbo (shift ~3.0 is common).\n\n## KSampler - The heart of inference\n\nKey settings:\n-  **Seed** ensures reproducibility ( same seed yields same output)\n- **Steps** 3 ‚Äì 12 (Turbo shines at low numbers, e.g. 8 ‚Äì 9)\n- **CFG** ~1.0 ‚Äì 3.0 (how strongly it follows prompt; 1.0 = balanced)\n- **Sampler** res_multistep or similar\n- **Scheduler** simple\n- **Denoise** 1.0 (full from-noise generation)\n\n\nIteratively: model predicts noise ‚Üí subtracts it ‚Üí image sharpens."
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 105,
      "type": "MarkdownNote",
      "pos": [
        12434.001405431305,
        1501.9999927189965
      ],
      "size": [
        372,
        194.390625
      ],
      "flags": {
        "collapsed": false
      },
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Step 5 - Decode & Save Image",
      "properties": {},
      "widgets_values": [
        "## VAE Decode\n\nTurns final latent back into viewable pixels.\n\n## Save Image\n\nOutputs the image to a file (e.g., with a prefix)."
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 109,
      "type": "MarkdownNote",
      "pos": [
        11126.001173818024,
        1501.9999927189965
      ],
      "size": [
        384,
        163.984375
      ],
      "flags": {
        "collapsed": false
      },
      "order": 8,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Step 2 - Set Image Size",
      "properties": {},
      "widgets_values": [
        "## Empty Latent Image\n\nYour starting \"noisy canvas\":\n\n- Select resolution (e.g., 864√ó1536 or 512√ó512).\n- Generates pure random noise as the base"
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 110,
      "type": "MarkdownNote",
      "pos": [
        11557.999091732087,
        1501.9999927189965
      ],
      "size": [
        384,
        349.171875
      ],
      "flags": {
        "collapsed": false
      },
      "order": 9,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Step 3 - Write a prompt ‚úçÔ∏è",
      "properties": {},
      "widgets_values": [
        "## CLIP Text Encode (Positive Prompt)\n\nCLIP Text Encode (Positive Prompt)\nInput desired description (e.g., \"anime illustration, young person with short black bob haircut, ...\").\n\n‚Üí Encoded via Qwen into a conditioning vector.\n\n## Conditioning Zero Out (Negative Prompt)\n\nWhat to avoid (e.g., \"blurry, ugly, deformed\").\n\n‚Üí Often zeroed out in Turbo workflows (model relies mainly on positive guidance)."
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 97,
      "type": "VAELoader",
      "pos": [
        10729.881691254059,
        964.9784263848593
      ],
      "size": [
        324,
        84
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            139
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader",
        "cnr_id": "comfy-core",
        "enableTabs": false,
        "hasSecondTab": false,
        "models": [
          {
            "directory": "vae",
            "name": "ae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors"
          }
        ],
        "secondTabOffset": 80,
        "secondTabText": "Send Back",
        "secondTabWidth": 65,
        "tabWidth": 65,
        "tabXOffset": 10,
        "ver": "0.3.73"
      },
      "widgets_values": [
        "ae.safetensors"
      ]
    },
    {
      "id": 106,
      "type": "MarkdownNote",
      "pos": [
        12626.400023195467,
        363.60005991042533
      ],
      "size": [
        225,
        8
      ],
      "flags": {
        "collapsed": true
      },
      "order": 11,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Hit run üëÜ",
      "properties": {},
      "widgets_values": [
        ""
      ],
      "color": "#222",
      "bgcolor": "#000"
    }
  ],
  "links": [
    [
      136,
      95,
      0,
      94,
      0,
      "MODEL"
    ],
    [
      137,
      103,
      0,
      99,
      0,
      "CONDITIONING"
    ],
    [
      138,
      102,
      0,
      98,
      0,
      "LATENT"
    ],
    [
      139,
      97,
      0,
      98,
      1,
      "VAE"
    ],
    [
      140,
      96,
      0,
      103,
      0,
      "CLIP"
    ],
    [
      141,
      94,
      0,
      102,
      0,
      "MODEL"
    ],
    [
      142,
      103,
      0,
      102,
      1,
      "CONDITIONING"
    ],
    [
      143,
      99,
      0,
      102,
      2,
      "CONDITIONING"
    ],
    [
      144,
      98,
      0,
      100,
      0,
      "IMAGE"
    ],
    [
      145,
      101,
      0,
      102,
      3,
      "LATENT"
    ]
  ],
  "groups": [
    {
      "id": 2,
      "title": "Image size",
      "bounding": [
        11130,
        510,
        384,
        936
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Prompt",
      "bounding": [
        11560,
        510,
        384,
        936
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "Load models",
      "bounding": [
        10710,
        510,
        372,
        936
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 6,
      "title": "Sampling",
      "bounding": [
        11990,
        510,
        396,
        936
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 7,
      "title": "Decode & Save the Image",
      "bounding": [
        12430,
        510,
        372,
        936
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "VHS_KeepIntermediate": true,
    "VHS_MetadataImage": true,
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "frontendVersion": "1.38.12",
    "workflowRendererVersion": "Vue",
    "ds": {
      "scale": 0.5644739300537773,
      "offset": [
        -10565.484636542149,
        -189.03581927600314
      ]
    }
  },
  "version": 0.4
}