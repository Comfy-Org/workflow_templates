{
  "id": "f7a250a1-53fb-496b-8c39-c60d9e764028",
  "revision": 0,
  "last_node_id": 48,
  "last_link_id": 82,
  "nodes": [
    {
      "id": 28,
      "type": "EmptyLatentImage",
      "pos": [
        -69.66666668548832,
        671.3333491672249
      ],
      "size": [
        307.59114583333337,
        106
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            78
          ]
        }
      ],
      "properties": {
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        1024,
        1024,
        1
      ]
    },
    {
      "id": 19,
      "type": "KSampler",
      "pos": [
        840.3333269241549,
        131.33331948456325
      ],
      "size": [
        290,
        405
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 79
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 39
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 40
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 78
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            10
          ]
        }
      ],
      "properties": {
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        856853657535148,
        "randomize",
        30,
        4,
        "er_sde",
        "simple",
        1
      ]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        910.3333560596592,
        641.3333766963631
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 10
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 11
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            82
          ]
        }
      ],
      "properties": {
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 46,
      "type": "SaveImage",
      "pos": [
        1170.3333042141144,
        141.33333365072383
      ],
      "size": [
        560,
        595
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 82
        }
      ],
      "outputs": [],
      "properties": {
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "cnr_id": "comfy-core",
        "ver": "0.11.1",
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 45,
      "type": "CLIPLoader",
      "pos": [
        -70,
        320
      ],
      "size": [
        307.59114583333337,
        106
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            80,
            81
          ]
        }
      ],
      "properties": {
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "cnr_id": "comfy-core",
        "ver": "0.11.0",
        "Node name for S&R": "CLIPLoader",
        "models": [
          {
            "name": "qwen_3_06b_base.safetensors",
            "url": "https://huggingface.co/circlestone-labs/Anima/resolve/main/split_files/text_encoders/qwen_3_06b_base.safetensors",
            "directory": "text_encoders"
          }
        ]
      },
      "widgets_values": [
        "qwen_3_06b_base.safetensors",
        "stable_diffusion",
        "default"
      ]
    },
    {
      "id": 15,
      "type": "VAELoader",
      "pos": [
        -70,
        490
      ],
      "size": [
        307.59114583333337,
        58
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            11
          ]
        }
      ],
      "properties": {
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "qwen_image_vae.safetensors",
            "url": "https://huggingface.co/circlestone-labs/Anima/resolve/main/split_files/vae/qwen_image_vae.safetensors",
            "directory": "vae"
          }
        ]
      },
      "widgets_values": [
        "qwen_image_vae.safetensors"
      ]
    },
    {
      "id": 44,
      "type": "UNETLoader",
      "pos": [
        -70,
        180
      ],
      "size": [
        307.59114583333337,
        82
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            79
          ]
        }
      ],
      "properties": {
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "cnr_id": "comfy-core",
        "ver": "0.11.0",
        "Node name for S&R": "UNETLoader",
        "models": [
          {
            "name": "anima-preview.safetensors",
            "url": "https://huggingface.co/circlestone-labs/Anima/resolve/main/split_files/diffusion_models/anima-preview.safetensors",
            "directory": "diffusion_models"
          }
        ]
      },
      "widgets_values": [
        "anima-preview.safetensors",
        "default"
      ]
    },
    {
      "id": 48,
      "type": "MarkdownNote",
      "pos": [
        -770,
        120
      ],
      "size": [
        660,
        670
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "## About Anima\n\n[Anima](https://huggingface.co/circlestone-labs/Anima) (2B-parameter, CircleStone/Comfy Org): Anime/non-photorealistic text-to-image model (no realism). Preview version trained on anime (Sept 2025 cut-off) + 800k art (no synthetic data); final version to improve details.\nComfyUI-native: 1MP optimal, 30-50 steps, CFG 4-5, supports er_sde/euler_a/dpmpp_2m_sde_gpu.\n\nSupports Danbooru tags (@artists), natural language, dataset tags; tag dropout applies. ComfyUI comparison workflow available.\n\nLimitations: poor realism (intentional), weak high-res/text, plain style.\n\n## Model Links (for Local Users)\n\n**text_encoders**\n\n- [qwen_3_06b_base.safetensors](https://huggingface.co/circlestone-labs/Anima/resolve/main/split_files/text_encoders/qwen_3_06b_base.safetensors)\n\n**vae**\n\n- [qwen_image_vae.safetensors](https://huggingface.co/circlestone-labs/Anima/resolve/main/split_files/vae/qwen_image_vae.safetensors)\n\n**diffusion_models**\n\n- [anima-preview.safetensors](https://huggingface.co/circlestone-labs/Anima/resolve/main/split_files/diffusion_models/anima-preview.safetensors)\n\n\n## Model Storage Location\n\n```\nðŸ“‚ ComfyUI/\nâ”œâ”€â”€ ðŸ“‚ models/\nâ”‚   â”œâ”€â”€ ðŸ“‚ text_encoders/\nâ”‚   â”‚   â””â”€â”€ qwen_3_06b_base.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ vae/\nâ”‚   â”‚   â””â”€â”€ qwen_image_vae.safetensors\nâ”‚   â””â”€â”€ ðŸ“‚ diffusion_models/\nâ”‚       â””â”€â”€ anima-preview.safetensors\n```\n\n## Report Issue\n\nNote: Please update ComfyUI first ([guide](https://docs.comfy.org/zh-CN/installation/update_comfyui)) and prepare required models. Desktop/Cloud ship stable builds; nightly-supported models may not be included yet, please wait for the next stable release.\n\n- Cannot run / runtime errors: [ComfyUI/issues](https://github.com/comfyanonymous/ComfyUI/issues)\n- UI / frontend issues: [ComfyUI_frontend/issues](https://github.com/Comfy-Org/ComfyUI_frontend/issues)\n- Workflow issues: [workflow_templates/issues](https://github.com/Comfy-Org/workflow_templates/issues)\n"
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 12,
      "type": "CLIPTextEncode",
      "pos": [
        290.33331808914284,
        621.3333483640421
      ],
      "size": [
        500,
        160
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 81
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            40
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "cnr_id": "comfy-core",
        "ver": "0.3.65",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "worst quality, low quality, score_1, score_2, score_3, blurry, jpeg artifacts, sepia"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 11,
      "type": "CLIPTextEncode",
      "pos": [
        290.33331808914284,
        171.33334113539559
      ],
      "size": [
        490,
        390
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 80
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            39
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "cnr_id": "comfy-core",
        "ver": "0.3.65",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "masterpiece, best quality, score_7, safe. An anime girl wearing a black tank-top and denim shorts is standing outdoors. She's holding a rectangular sign out in front of her that reads \"ANIMA\". She's looking at the viewer with a smile. The background features some trees and blue sky with clouds."
      ],
      "color": "#232",
      "bgcolor": "#353"
    }
  ],
  "links": [
    [
      10,
      19,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      11,
      15,
      0,
      8,
      1,
      "VAE"
    ],
    [
      39,
      11,
      0,
      19,
      1,
      "CONDITIONING"
    ],
    [
      40,
      12,
      0,
      19,
      2,
      "CONDITIONING"
    ],
    [
      78,
      28,
      0,
      19,
      3,
      "LATENT"
    ],
    [
      79,
      44,
      0,
      19,
      0,
      "MODEL"
    ],
    [
      80,
      45,
      0,
      11,
      0,
      "CLIP"
    ],
    [
      81,
      45,
      0,
      12,
      0,
      "CLIP"
    ],
    [
      82,
      8,
      0,
      46,
      0,
      "IMAGE"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step 1 - Load Models",
      "bounding": [
        -90,
        90,
        350,
        490
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step 2 - Image Size(1MP))",
      "bounding": [
        -90,
        600,
        350,
        190
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step3 - Prompt",
      "bounding": [
        280,
        90,
        520,
        700
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.5339594538205411,
      "offset": [
        2126.814384792746,
        490.29929089124096
      ]
    },
    "workflowRendererVersion": "LG",
    "frontendVersion": "1.37.11",
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}