{
  "id": "7cbcec68-7fa6-47bb-a38a-da689949a001",
  "revision": 0,
  "last_node_id": 104,
  "last_link_id": 188,
  "nodes": [
    {
      "id": 27,
      "type": "EmptySD3LatentImage",
      "pos": [
        -170,
        570
      ],
      "size": [
        337.76861572265625,
        106
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            51
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "EmptySD3LatentImage"
      },
      "widgets_values": [
        1024,
        1024,
        1
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 37,
      "type": "UNETLoader",
      "pos": [
        -170,
        90
      ],
      "size": [
        337.76861572265625,
        82
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            58
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "UNETLoader"
      },
      "widgets_values": [
        "preliminary-dev-kontext.sft",
        "fp8_e4m3fn"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [
        -170,
        410
      ],
      "size": [
        337.76861572265625,
        58
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            61,
            67
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "ae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/resolve/main/split_files/vae/ae.safetensors",
            "directory": "vae"
          }
        ]
      },
      "widgets_values": [
        "ae.safetensors"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 42,
      "type": "FluxKontextImageScale",
      "pos": [
        210,
        750
      ],
      "size": [
        187.75448608398438,
        26
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 66
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            65,
            68
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "FluxKontextImageScale"
      },
      "widgets_values": []
    },
    {
      "id": 41,
      "type": "VAEEncode",
      "pos": [
        210,
        650
      ],
      "size": [
        190,
        50
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 65
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 67
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            64
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "VAEEncode"
      },
      "widgets_values": []
    },
    {
      "id": 100,
      "type": "MarkdownNote",
      "pos": [
        -720,
        60
      ],
      "size": [
        520,
        370
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "[tutorial](http://docs.comfy.org/tutorials/flux/flux-1-kontext) | [æ•™ç¨‹](http://docs.comfy.org/zh-CN/tutorials/flux/flux-1-kontext)\n\n**diffusion model**\n\n[to be updated]\n\n**vae**\n\n- [ae.safetensors](https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/blob/main/split_files/vae/ae.safetensors)\n\n**text encoder**\n\n- [clip_l.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/blob/main/clip_l.safetensors)\n- [t5xxl_fp16.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors) or [t5xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors)\n\nModel Storage Location\n\n```\nðŸ“‚ ComfyUI/\nâ”œâ”€â”€ ðŸ“‚ models/\nâ”‚   â”œâ”€â”€ ðŸ“‚ diffusion_models/\nâ”‚   â”‚   â””â”€â”€ [to be updated]\nâ”‚   â”œâ”€â”€ ðŸ“‚ vae/\nâ”‚   â”‚   â””â”€â”€ ae.safetensor\nâ”‚   â””â”€â”€ ðŸ“‚ text_encoders/\nâ”‚       â”œâ”€â”€ clip_l.safetensors\nâ”‚       â””â”€â”€ t5xxl_fp16.safetensors æˆ–è€… t5xxl_fp8_e4m3fn_scaled.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 89,
      "type": "MarkdownNote",
      "pos": [
        -410,
        740
      ],
      "size": [
        210,
        160
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "You can upload the original pictures that are needed for editing, as well as pictures for reference of the style, etc.\n\nå¯ä»¥ä¸Šä¼ éœ€è¦ç”¨äºŽç¼–è¾‘çš„åŽŸå›¾ï¼Œå‚è€ƒé£Žæ ¼çš„å›¾ç‰‡ç­‰ç­‰"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 101,
      "type": "MarkdownNote",
      "pos": [
        -170,
        -140
      ],
      "size": [
        330,
        140
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "About Load Diffusion Model",
      "properties": {},
      "widgets_values": [
        "Here, the full version model is used. Therefore, the **Load Diffusion model** node is set to **fp8_e4m3fn** so that it can run successfully on GPU like the 4090. If you need the original quality, please set it to **default**.\n\nè¿™é‡Œä½¿ç”¨äº†å®Œæ•´ç‰ˆçš„æ¨¡åž‹ï¼Œæ‰€ä»¥ **Load Diffusion model** node è¢«è®¾ç½®æˆäº† **fp8_e4m3fn** ä»¥ä¾¿åœ¨ç±»ä¼¼ 4090 è¿™æ ·çš„æ˜¾å¡ä¸Šä¹Ÿèƒ½å¤ŸæˆåŠŸè¿è¡Œï¼Œå¦‚æžœä½ éœ€è¦åŽŸå§‹è´¨é‡çš„ï¼Œè¯·æŠŠå®ƒè®¾ç½®æˆ **default**"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 104,
      "type": "MarkdownNote",
      "pos": [
        660,
        -280
      ],
      "size": [
        410,
        270
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Flux Kontext æç¤ºè¯æŠ€å·§",
      "properties": {},
      "widgets_values": [
        "\n## Flux Kontext æç¤ºè¯æŠ€å·§\n\nä½¿ç”¨è‹±æ–‡\n\n### 1. åŸºç¡€ä¿®æ”¹\n- ç®€å•ç›´æŽ¥ï¼š`\"Change the car color to red\"`\n- ä¿æŒé£Žæ ¼ï¼š`\"Change to daytime while maintaining the same style of the painting\"`\n\n### 2. é£Žæ ¼è½¬æ¢\n**åŽŸåˆ™ï¼š**\n- æ˜Žç¡®å‘½åé£Žæ ¼ï¼š`\"Transform to Bauhaus art style\"`\n- æè¿°ç‰¹å¾ï¼š`\"Transform to oil painting with visible brushstrokes, thick paint texture\"`\n- ä¿ç•™æž„å›¾ï¼š`\"Change to Bauhaus style while maintaining the original composition\"`\n\n### 3. è§’è‰²ä¸€è‡´æ€§\n**æ¡†æž¶ï¼š**\n- å…·ä½“æè¿°ï¼š`\"The woman with short black hair\"`è€Œéž`\"å¥¹\"`\n- ä¿ç•™ç‰¹å¾ï¼š`\"while maintaining the same facial features, hairstyle, and expression\"`\n- åˆ†æ­¥ä¿®æ”¹ï¼šå…ˆæ”¹èƒŒæ™¯ï¼Œå†æ”¹åŠ¨ä½œ\n\n### 4. æ–‡æœ¬ç¼–è¾‘\n- ä½¿ç”¨å¼•å·ï¼š`\"Replace 'joy' with 'BFL'\"`\n- ä¿æŒæ ¼å¼ï¼š`\"Replace text while maintaining the same font style\"`\n\n## å¸¸è§é—®é¢˜è§£å†³\n\n### è§’è‰²å˜åŒ–è¿‡å¤§\nâŒ é”™è¯¯ï¼š`\"Transform the person into a Viking\"`\nâœ… æ­£ç¡®ï¼š`\"Change the clothes to be a viking warrior while preserving facial features\"`\n\n### æž„å›¾ä½ç½®æ”¹å˜\nâŒ é”™è¯¯ï¼š`\"Put him on a beach\"`\nâœ… æ­£ç¡®ï¼š`\"Change the background to a beach while keeping the person in the exact same position, scale, and pose\"`\n\n### é£Žæ ¼åº”ç”¨ä¸å‡†ç¡®\nâŒ é”™è¯¯ï¼š`\"Make it a sketch\"`\nâœ… æ­£ç¡®ï¼š`\"Convert to pencil sketch with natural graphite lines, cross-hatching, and visible paper texture\"`\n\n## æ ¸å¿ƒåŽŸåˆ™\n\n1. **å…·ä½“æ˜Žç¡®** - ä½¿ç”¨ç²¾ç¡®æè¿°ï¼Œé¿å…æ¨¡ç³Šè¯æ±‡\n2. **åˆ†æ­¥ç¼–è¾‘** - å¤æ‚ä¿®æ”¹åˆ†ä¸ºå¤šä¸ªç®€å•æ­¥éª¤\n3. **æ˜Žç¡®ä¿ç•™** - è¯´æ˜Žå“ªäº›è¦ä¿æŒä¸å˜\n4. **åŠ¨è¯é€‰æ‹©** - ç”¨\"æ›´æ”¹\"ã€\"æ›¿æ¢\"è€Œéž\"è½¬æ¢\"\n\n## æœ€ä½³å®žè·µæ¨¡æ¿\n\n**å¯¹è±¡ä¿®æ”¹ï¼š**\n`\"Change [object] to [new state], keep [content to preserve] unchanged\"`\n\n**é£Žæ ¼è½¬æ¢ï¼š**\n`\"Transform to [specific style], while maintaining [composition/character/other] unchanged\"`\n\n**èƒŒæ™¯æ›¿æ¢ï¼š**\n`\"Change the background to [new background], keep the subject in the exact same position and pose\"`\n\n**æ–‡æœ¬ç¼–è¾‘ï¼š**\n`\"Replace '[original text]' with '[new text]', maintain the same font style\"`\n\n> **è®°ä½ï¼š** è¶Šå…·ä½“è¶Šå¥½ï¼ŒKontext æ“…é•¿ç†è§£è¯¦ç»†æŒ‡ä»¤å¹¶ä¿æŒä¸€è‡´æ€§ã€‚"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 38,
      "type": "DualCLIPLoader",
      "pos": [
        -170,
        230
      ],
      "size": [
        337.76861572265625,
        130
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            59,
            60
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "DualCLIPLoader",
        "models": [
          {
            "name": "clip_l.safetensors",
            "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors",
            "directory": "text_encoders"
          },
          {
            "name": "t5xxl_fp8_e4m3fn_scaled.safetensors",
            "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors",
            "directory": "text_encoders"
          }
        ]
      },
      "widgets_values": [
        "clip_l.safetensors",
        "t5xxl_fp16.safetensors",
        "flux",
        "default"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 44,
      "type": "PreviewImage",
      "pos": [
        210,
        830
      ],
      "size": [
        330,
        280
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 68
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "PreviewImage"
      },
      "widgets_values": []
    },
    {
      "id": 31,
      "type": "KSampler",
      "pos": [
        670,
        40
      ],
      "size": [
        315,
        262
      ],
      "flags": {},
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 58
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 57
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 55
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 51
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            52
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        156106254303272,
        "randomize",
        20,
        1,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1010,
        40
      ],
      "size": [
        190,
        46
      ],
      "flags": {
        "collapsed": false
      },
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 52
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 61
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            9
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 40,
      "type": "FluxKontext",
      "pos": [
        200,
        240
      ],
      "size": [
        211.60000610351562,
        46
      ],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 62
        },
        {
          "name": "latent",
          "shape": 7,
          "type": "LATENT",
          "link": 64
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            63
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "FluxKontext"
      },
      "widgets_values": []
    },
    {
      "id": 35,
      "type": "FluxGuidance",
      "pos": [
        200,
        330
      ],
      "size": [
        210,
        58
      ],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 63
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            57
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "FluxGuidance"
      },
      "widgets_values": [
        2.5
      ]
    },
    {
      "id": 33,
      "type": "CLIPTextEncode",
      "pos": [
        210,
        430
      ],
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {
        "collapsed": true
      },
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 60
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            55
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        ""
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 103,
      "type": "MarkdownNote",
      "pos": [
        200,
        -280
      ],
      "size": [
        410,
        270
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Flux Kontext Prompt Techniques",
      "properties": {},
      "widgets_values": [
        "\n## Flux Kontext Prompt Techniques\n\n### 1. Basic Modifications\n- Simple and direct: `\"Change the car color to red\"`\n- Maintain style: `\"Change to daytime while maintaining the same style of the painting\"`\n\n### 2. Style Transfer\n**Principles:**\n- Clearly name style: `\"Transform to Bauhaus art style\"`\n- Describe characteristics: `\"Transform to oil painting with visible brushstrokes, thick paint texture\"`\n- Preserve composition: `\"Change to Bauhaus style while maintaining the original composition\"`\n\n### 3. Character Consistency\n**Framework:**\n- Specific description: `\"The woman with short black hair\"` instead of \"she\"\n- Preserve features: `\"while maintaining the same facial features, hairstyle, and expression\"`\n- Step-by-step modifications: Change background first, then actions\n\n### 4. Text Editing\n- Use quotes: `\"Replace 'joy' with 'BFL'\"`\n- Maintain format: `\"Replace text while maintaining the same font style\"`\n\n## Common Problem Solutions\n\n### Character Changes Too Much\nâŒ Wrong: `\"Transform the person into a Viking\"`\nâœ… Correct: `\"Change the clothes to be a viking warrior while preserving facial features\"`\n\n### Composition Position Changes\nâŒ Wrong: `\"Put him on a beach\"`\nâœ… Correct: `\"Change the background to a beach while keeping the person in the exact same position, scale, and pose\"`\n\n### Style Application Inaccuracy\nâŒ Wrong: `\"Make it a sketch\"`\nâœ… Correct: `\"Convert to pencil sketch with natural graphite lines, cross-hatching, and visible paper texture\"`\n\n## Core Principles\n\n1. **Be Specific and Clear** - Use precise descriptions, avoid vague terms\n2. **Step-by-step Editing** - Break complex modifications into multiple simple steps\n3. **Explicit Preservation** - State what should remain unchanged\n4. **Verb Selection** - Use \"change\", \"replace\" rather than \"transform\"\n\n## Best Practice Templates\n\n**Object Modification:**\n`\"Change [object] to [new state], keep [content to preserve] unchanged\"`\n\n**Style Transfer:**\n`\"Transform to [specific style], while maintaining [composition/character/other] unchanged\"`\n\n**Background Replacement:**\n`\"Change the background to [new background], keep the subject in the exact same position and pose\"`\n\n**Text Editing:**\n`\"Replace '[original text]' with '[new text]', maintain the same font style\"`\n\n> **Remember:** The more specific, the better. Kontext excels at understanding detailed instructions and maintaining consistency. "
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 43,
      "type": "LoadImage",
      "pos": [
        -170,
        770
      ],
      "size": [
        340,
        326
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            66
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "input (1).png",
        "image"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        570,
        350
      ],
      "size": [
        640,
        750
      ],
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 9
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38"
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        200,
        40
      ],
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 59
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            62
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "Using this style, maintain the texture and characteristics of the character, and change the character to a cat. "
      ],
      "color": "#232",
      "bgcolor": "#353"
    }
  ],
  "links": [
    [
      9,
      8,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      51,
      27,
      0,
      31,
      3,
      "LATENT"
    ],
    [
      52,
      31,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      55,
      33,
      0,
      31,
      2,
      "CONDITIONING"
    ],
    [
      57,
      35,
      0,
      31,
      1,
      "CONDITIONING"
    ],
    [
      58,
      37,
      0,
      31,
      0,
      "MODEL"
    ],
    [
      59,
      38,
      0,
      6,
      0,
      "CLIP"
    ],
    [
      60,
      38,
      0,
      33,
      0,
      "CLIP"
    ],
    [
      61,
      39,
      0,
      8,
      1,
      "VAE"
    ],
    [
      62,
      6,
      0,
      40,
      0,
      "CONDITIONING"
    ],
    [
      63,
      40,
      0,
      35,
      0,
      "CONDITIONING"
    ],
    [
      64,
      41,
      0,
      40,
      1,
      "LATENT"
    ],
    [
      65,
      42,
      0,
      41,
      0,
      "IMAGE"
    ],
    [
      66,
      43,
      0,
      42,
      0,
      "IMAGE"
    ],
    [
      67,
      39,
      0,
      41,
      1,
      "VAE"
    ],
    [
      68,
      42,
      0,
      44,
      0,
      "IMAGE"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Load models here",
      "bounding": [
        -180,
        20,
        360,
        460
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Image size",
      "bounding": [
        -180,
        500,
        357.76861572265625,
        189.60000610351562
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Upload image for editing",
      "bounding": [
        -180,
        700,
        360,
        409.6000061035156
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.4240976183724851,
      "offset": [
        1335.6484017165888,
        609.7968143741401
      ]
    },
    "frontendVersion": "1.20.7",
    "groupNodes": {}
  },
  "version": 0.4
}